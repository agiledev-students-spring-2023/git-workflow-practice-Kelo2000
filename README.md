# Git Workflow Practice

## Article: [Tesla ‘full self-driving’ triggered an eight-car crash, a driver tells police:](https://www.cnn.com/2022/12/21/business/tesla-fsd-8-car-crash/index.html)

## Comments on the Article: 
The recent crash involving a Tesla vehicle while in Full Self-Driving (FSD) mode raises concerns about the safety of advanced driver assistance systems. The incident, which is now being investigated by the National Highway Traffic Safety Administration (NHTSA), marks the first known crash involving a Tesla vehicle while in FSD mode and highlights the need for caution when using such systems. Despite Tesla's statements that drivers must always be in control of the vehicle and ready to take over if necessary, some owners have reported relying heavily on the system. This raises questions about the level of trust that should be placed in advanced driver assistance systems and highlights the importance of ensuring their safety before they are made widely available to the public. The incident also serves as a reminder of the responsibility that falls on both the car manufacturers and the drivers to ensure the safe operation of vehicles on the road.

#### Bishnu's comment
This incident reminds me of a YouTube video made by MKBHD regarding the state of Tesla's autopilot. While he wasn't testing the "full auto-pilot" mode, he clearly showed some of the major issues with self-driving cars. One of the biggest issues is the fact that the vast majority of vehicles are operated by humans, thus there is a certain level of unpredictability. This is not related to Tesla but other self-driving cars as well. The biggest challenge in the development of self-driving cars lies in the transitionary period, after which the technology can be considered safe.